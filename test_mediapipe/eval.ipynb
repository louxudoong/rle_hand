{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anno_xyz len： 3960\n",
      "anno_K len： 3960\n",
      "img list len： 3960\n",
      "AUG OFF.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0582ab451cb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mdetection_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhand_landmarks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# cal mAP and rmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from rlepose.models import builder\n",
    "from rlepose.utils.config import update_config\n",
    "from rlepose.utils.valid_utils_lxd import calculate_error_distance_avg, calculate_RMSE, calculate_PCK, paint\n",
    "\n",
    "\n",
    "cfg = update_config(\"../configs/256x192_res50_regress-flow_freihand.yaml\")\n",
    "device = torch.device('cuda')\n",
    "# m = builder.build_sppe(cfg.MODEL, preset_cfg=cfg.DATA_PRESET)  # 根据cfg的配置信息构建模型\n",
    "\n",
    "# m.load_state_dict(torch.load(\"/home/louxd/ldlib/res-loglikelihood-regression-master/weights/model_0918_233.pth\", map_location='cpu'), \n",
    "#                   strict=True)  # 加载权重\n",
    "\n",
    "model_path = './hand_landmarker.task'\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                       num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    gt_val_dataset = builder.build_dataset(cfg.DATASET.VAL, preset_cfg=cfg.DATA_PRESET, train=False, heatmap2coord=cfg.TEST.HEATMAP2COORD)\n",
    "    gt_val_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        gt_val_dataset, num_replicas=1, rank=0)\n",
    "\n",
    "    gt_val_loader = torch.utils.data.DataLoader(\n",
    "        gt_val_dataset, batch_size=16, shuffle=False, num_workers=20, drop_last=False, sampler=gt_val_sampler)\n",
    "    \n",
    "    \n",
    "    rmse_list = []\n",
    "    pck_pix = []\n",
    "    pck_norm = []\n",
    "    err_pix = []\n",
    "\n",
    "    for index, (inps, labels) in enumerate(gt_val_loader):\n",
    "        inps = inps.cuda(device)\n",
    "        for k, _ in labels.items():\n",
    "            if k == 'type':\n",
    "                continue\n",
    "            \n",
    "            labels[k] = labels[k].cuda(device)\n",
    "\n",
    "        # output = m(inps, labels)\n",
    "        for i in range(len(inps)):\n",
    "            imgi = inps[i].cpu().numpy()\n",
    "            imgi = np.transpose(imgi, (1, 2, 0))\n",
    "            imgi = (imgi + np.array([0.480, 0.457, 0.406], dtype=np.float32)) * np.array([255., 255., 255.], dtype=np.float32)\n",
    "            imgi = cv2.cvtColor(imgi, cv2.COLOR_BGR2RGB) \n",
    "            imgi = imgi.astype(np.uint8)\n",
    "            img_h, img_w, _ = imgi.shape\n",
    "            # kpts_pre_i = np.array([(kpt + [0.5, 0.5]) * [img_w, img_h] for kpt in kpts_pre[i]])\n",
    "            # kpts_gt_i = np.array([(kpt + [0.5, 0.5]) * [img_w, img_h] for kpt in kpts_gt[i]])\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=imgi)\n",
    "            detection_result = detector.detect(mp_image)\n",
    "            hand_lm = detection_result.hand_landmarks[0]\n",
    "            pts_i = []\n",
    "\n",
    "            for lm in hand_lm:\n",
    "                x = lm.x * img_w\n",
    "                y = lm.y * img_h\n",
    "                pts_i.append([x, y])\n",
    "\n",
    "            imagei_pre = imgi.copy()\n",
    "            # imagei_gt = imgi.copy()\n",
    "            imagei_pre = paint(imagei_pre, pts_i)\n",
    "            # imagei_gt = paint(imagei_gt, kpts_gt_i)\n",
    "            cv2.imwrite(f'./exp/output/{index}_{i}_pre.jpg', imagei_pre)\n",
    "            cv2.imwrite(f'./exp/output/{index}_{i}_gt.jpg', imagei_gt)\n",
    "\n",
    "            # cal mAP and rmse\n",
    "            # rmsei = compute_RMSE(kpts_pre_i, kpts_gt_i)\n",
    "            # mse_i = mean_squared_error(kpts_pre_i, kpts_gt_i)\n",
    "            # rmse_i = np.sqrt(mse_i)\n",
    "            # _, rmse_i = calculate_RMSE(kpts_pre_i, kpts_gt_i)\n",
    "            # # oksi = calculate_oks_pt2(kpts_pre_i, kpts_gt_i)\n",
    "            # pck_pix_i, pck_norm_i = calculate_PCK(kpts_pre_i, kpts_gt_i)\n",
    "            # err_pix_i = calculate_error_distance_avg(kpts_pre_i, kpts_gt_i)\n",
    "            # rmse_list.append(rmse_i)\n",
    "            # pck_pix.append(pck_pix_i)\n",
    "            # pck_norm.append(pck_norm_i)\n",
    "            # err_pix.append(err_pix_i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     if isinstance(inps, list):\n",
    "    #         batch_size = inps[0].size(0)\n",
    "    #     else:\n",
    "    #         batch_size = inps.size(0)\n",
    "\n",
    "    #     kpts_gt = labels['target_uv'].cpu().numpy().reshape(-1, 21, 2) # size * 42\n",
    "    #     kpts_pre = output.pred_jts.cpu().numpy().reshape(-1, 21, 2)\n",
    "\n",
    "    #     # print & draw\n",
    "    #     for i in range(len(inps)):\n",
    "    #         #print(f'batch:{batch_idx}_{i}')\n",
    "    #         imgi = inps[i].cpu().numpy()\n",
    "    #         imgi = np.transpose(imgi, (1, 2, 0))\n",
    "    #         imgi = (imgi + np.array([0.480, 0.457, 0.406], dtype=np.float32)) * np.array([255., 255., 255.], dtype=np.float32)\n",
    "    #         imgi = cv2.cvtColor(imgi, cv2.COLOR_BGR2RGB) \n",
    "    #         img_h, img_w, _ = imgi.shape\n",
    "    #         kpts_pre_i = np.array([(kpt + [0.5, 0.5]) * [img_w, img_h] for kpt in kpts_pre[i]])\n",
    "    #         kpts_gt_i = np.array([(kpt + [0.5, 0.5]) * [img_w, img_h] for kpt in kpts_gt[i]])\n",
    "\n",
    "\n",
    "    #         # cal mAP and rmse\n",
    "    #         # rmsei = compute_RMSE(kpts_pre_i, kpts_gt_i)\n",
    "    #         # mse_i = mean_squared_error(kpts_pre_i, kpts_gt_i)\n",
    "    #         # rmse_i = np.sqrt(mse_i)\n",
    "    #         _, rmse_i = calculate_RMSE(kpts_pre_i, kpts_gt_i)\n",
    "    #         # oksi = calculate_oks_pt2(kpts_pre_i, kpts_gt_i)\n",
    "    #         pck_pix_i, pck_norm_i = calculate_PCK(kpts_pre_i, kpts_gt_i)\n",
    "    #         err_pix_i = calculate_error_distance_avg(kpts_pre_i, kpts_gt_i)\n",
    "    #         rmse_list.append(rmse_i)\n",
    "    #         pck_pix.append(pck_pix_i)\n",
    "    #         pck_norm.append(pck_norm_i)\n",
    "    #         err_pix.append(err_pix_i)\n",
    "\n",
    "    #         # imagei_pre = imgi.copy()\n",
    "    #         # imagei_gt = imgi.copy()\n",
    "    #         # imagei_pre = paint(imagei_pre, kpts_pre_i)\n",
    "    #         # imagei_gt = paint(imagei_gt, kpts_gt_i)\n",
    "    #         # cv2.imwrite(f'./exp/output/{index}_{i}_pre.jpg', imagei_pre)\n",
    "    #         # cv2.imwrite(f'./exp/output/{index}_{i}_gt.jpg', imagei_gt)\n",
    "\n",
    "\n",
    "    # rmse = sum(rmse_list) / len(rmse_list)\n",
    "    # pck_pix = np.mean(pck_pix, axis=0)\n",
    "    # pck_norm = np.mean(pck_norm, axis=0)\n",
    "    # err_pix = np.mean(err_pix)\n",
    "    # # mAP_info_str = calculate_mAP(oks_list)\n",
    "\n",
    "    # # ap = mAP_info_str['mAP']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormalizedLandmark(x=0.8822426199913025, y=0.49387818574905396, z=8.636168900011398e-07, visibility=0.0, presence=0.0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NormalizedLandmark' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8b08b9bc585d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# rescaled_landmarks = [(int(x * img_w), int(y * img_h)) for x, y, _, _, _ in lm]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NormalizedLandmark' object is not iterable"
     ]
    }
   ],
   "source": [
    "a = detection_result.hand_landmarks[0]\n",
    "rescaled_result = []\n",
    "for lm in a:\n",
    "    x = lm.x * img_w\n",
    "    y = lm.y * img_h\n",
    "    rescaled_result.append([x, y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormalizedLandmark(x=0.8822426199913025, y=0.49387818574905396, z=8.636168900011398e-07, visibility=0.0, presence=0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_result.hand_landmarks[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
